\chapter{Числовые характеристики распределения случайных величин}
\setcounter{equation}{0}
\section{Математическое ожидание случайной величины}
\begin{definition}
  Математическим ожиданием случайной величины $\xi$ на вероятностном пространстве $(\Omega, \mathcal{F}, \Prob)$ будем называть интеграл Лебега:
  \[
    \MExpect_{\xi} = \int\limits_{\Omega} \xi(\omega) d \Prob(\omega), \text{ при этом, если } \int\limits_{\Omega} | \xi(\omega) | d \Prob < +\infty
  \]
  T.e. если интеграл конечен. Иначе случайная величина математического ожидания не имеет.
  \[
    \exists \MExpect_{\xi} \Leftrightarrow \MExpect_{|\xi|} < +\infty
  \]
  \[
    \exists \MExpect_{\xi} \Rightarrow \forall A \in \mathcal{F} \;\;\exists \int\limits_A \xi(\omega) d \Prob = \int\limits_{\Omega} \xi \cdot I_A d \Prob = \MExpect \left[ \xi \cdot I_A \right]
  \]
  \[
    \MExpect_{I_A} = \int\limits_{\Omega} I_A (\omega) d \Prob = \int\limits_A d \Prob = \Prob(A)
  \]
\end{definition}
\subsection{Свойства математического ожидания}
\begin{enumerate}
  \item Пусть $a, b$ --- константы. Тогда $\MExpect_a = a, \MExpect \left[ b \cdot \xi \right] = b \cdot \MExpect_{\xi}$
  \item $|\MExpect_{\xi}| \leqslant \MExpect_{|\xi|}$
  \item $\MExpect \left[ \xi + \eta \right] = \MExpect_{\xi} + \MExpect_{\eta}$
  \item $\forall \varepsilon > 0 : |\xi| \leqslant \varepsilon \Rightarrow |\MExpect_{\xi}| \leqslant \varepsilon$
  \begin{proof} \textit{(Свойство 4)}
    \[
      |\MExpect_{\xi}| \leqslant \MExpect_{|\xi|} = \int\limits_{\Omega} |\xi| d \Prob \leqslant \varepsilon \int\limits_{\Omega} d \Prob = \varepsilon \cdot \Prob(\Omega) = \varepsilon
    \]
  \end{proof}
  \item \textbf{Неравенство Чебышёва.} Пусть $\xi \geqslant 0$ --- случайная величина, $t > 0$, $t \in \mathbb{R}^1$. Тогда
  \[
    \Prob \{ \xi \geqslant t \} \leqslant \frac{\MExpect \xi}{t}
  \]
  Рассмотрим
  \[
    \Prob \{ \xi \geqslant t \} = \int\limits_{\{ \omega: \xi(\omega) \geqslant t\}} d \Prob \leqslant \int\limits_{\{ \xi \geqslant t \}} \frac{\xi(\omega)}{t} d \Prob \leqslant \frac{1}{t} \int\limits_{\Omega} \xi(\Omega) d \Prob = \frac{\MExpect \xi}{t}
  \]
\end{enumerate}
\begin{conclusion}
  $g(x)$ --- борелевская функция, $x \in (0, +\infty)$. $g(x)$ монотонно возрастает, $g(x) \geqslant 0$, $\xi$ --- случайная величина. $t > 0: g(t) \not= 0$
  \[
    \Prob \{ |\xi| \geqslant t \} \leqslant \frac{\MExpect [g(|\xi|)]}{g(t)}
  \]
  \[
    \Prob \{ |\xi| \geqslant t \} = \Prob \{ g(|\xi|) \geqslant g(t) \} \leqslant \frac{\MExpect g(|\xi|)}{g(t)}
  \]
  Пусть $g(x) = x^2$. $x \in (0, +\infty)$:
  \[
    \Prob \{ |\xi| \leqslant t \} \leqslant \frac{\MExpect \xi^2}{t^2}, t > 0
  \]
  \[
    g(x_1, \ldots, x_n), \; g: \mathbb{R}^n \to \mathbb{R}^1
  \]
  \[
    \forall B \in \mathcal{B} (\mathbb{R}^1) : g^{-1}(B) \in \mathcal{B} (\mathbb{R}^n)
  \]
  \[
    g^{-1} (B) = \{ x, x \in \mathbb{R}^n : g(x) \in B \}
  \]
  \[
    \overline{\xi} = (\xi_1, \ldots, \xi_n), g(\overline{\xi}) : \Omega \to \mathbb{R}^1, \xi_i: \Omega \to \mathbb{R}^1
  \]
\end{conclusion}
\begin{theorem} \textit{(О вычислении математического ожидания случайной величины.)} Пусть задан вектор случайных величин $\overline{\xi} = (\xi_1, \ldots, \xi_n)$ на вероятностном пространстве $(\Omega, \mathcal{F}, \mathcal{P})$. \\
$g(x) : \mathbb{R}^n \to \mathbb{R}^1$, $x \in \mathbb{R}^n$, $g$ --- борелевская функция. Тогда на конкретном вероятностном пространстве задан интеграл Лебега
\[
  \MExpect g(\overline\xi) = \int\limits_{\mathbb{R}^n} g(x) d \mathcal{P}_{\overline{\xi}} (x),\; x \in \mathbb{R}^n
\]
По определению математического ожидания задан также интеграл Лебега, но на абстрактном пространстве элементарных событий.
\[
  \int\limits_{\Omega} g (\overline{\xi}(\omega)) d \Prob (\omega)
\]
Мы понимаем равенство следующим образом: если первый интеграл существует, то второй интеграл так же существует и ему равен.
\end{theorem}
\begin{conclusion}
  Пусть задан дискретный вектор случайных величин $\overline{\xi} = (\xi_1, \ldots, \xi_n)$, возможные значения --- ${\{ x^{(j)} \}}_{j = 1, 2, \ldots} $,
  $g : \mathbb{R}^n \to \mathbb{R}^1$ --- борелевская функция. Тогда математическое ожидание
  \[
    \MExpect g(\overline{\xi}) = \sum\limits_{x^{(j)} \in {\{ x^{(i)} \}}_{i = 1, 2, \ldots}} g(x^{(j)}) \cdot \Prob \{ \overline{\xi} = x^{(j)} \}
  \]
  \[
    \MExpect_{\xi} = \sum\limits_j x_j \cdot \Prob \{ \xi = x_j \}
  \]
\end{conclusion}
\begin{conclusion}
  Пусть задан абсолютно непрерывный вектор случайных величин $\overline{\xi} = (\xi_1, \ldots, \xi_n)$, $f_{\overline{\xi}}(\underbrace{x_1, \ldots, x_n}_{x}), x \in \mathbb{R}^n$, $g$ --- борелевская функция. Определим:
  \[
    \MExpect g(\overline{\xi}) = \int\limits_{\mathbb{R}^n} g(x) f_{\overline{\xi}} (x) dx
  \]
  \[
    \MExpect_{\xi} = \int\limits_{-\infty}^{+\infty} x \cdot f_{\xi} (x) dx
  \]
\end{conclusion}
\begin{example} \textit{Равномерное распределение.}
  $\xi \sim U [a, b]$.
  \[
    f_{\xi} (x) = \begin{dcases*}
    \frac{1}{b-a},\; x \in [a, b] \\
    0,\; x \not\in [a, b]
  \end{dcases*}
  \]
  \[
    \MExpect_{\xi} = \int\limits_a^b \frac{x}{b-a} dx = \frac{a+b}{2}
  \]
\end{example}
\begin{example} \textit{Дискретная случайная величина (бернуллиевская), задающая некоторые распределение.}
  \[
    q = 0,\; p = 1;\; p + q = 1,\; \MExpect_{\xi} = p
  \]
  Рассмотрим биномиальную случайную величину. Пусть $\mu_n$ --- число появления <<успеха>> в $n$ испытаниях Бернулли. Также пусть $\xi_k$ --- число появления успеха в $k$-ом испытании Бернулли
  \[
    \mu_n = \sum\limits_{k = 1}^n \xi_k
  \]
  \[
    \MExpect_{\mu_n} = \MExpect \left[ \sum\limits_{k = 1}^n  \xi_k \right] = \sum\limits_{k = 1}^n \MExpect_{\xi_k} = np
  \]
\end{example}
\begin{example} \textit{Распределение вероятностей случайных величин Пуассона.} $\xi \sim \Prob [a], a > 0$
  \[
    \MExpect_{\xi} = \sum\limits_{k = 0}^{\infty} k \cdot \frac{a^k}{k \ !} e^{-a} = a \cdot e^{-a} \sum\limits_{k = 0}^{\infty} \frac{a^{k-1}}{(k-1) \ !} = a
  \]
\end{example}
\begin{example} \textit{Распределение вероятностей случайных величин Коши.}
  $a > 0$
  \[
    f_{\xi} (x) = \frac{a}{\pi (x^2 + a^2)},\; x \in \mathbb{R}^1
  \]
  \[
    F_{\xi} (x) = \frac{1}{2} + \frac{1}{\pi} \arctg \frac{x}{a}
  \]
  Закон распределения Коши не имеет моментов и математического ожидания. Рассмотрим $\MExpect_{|\xi|}$
  \[
    \MExpect_{|\xi|} = \int\limits_{-\infty}^{+\infty} |x| \cdot f_{\xi} (x) dx
  \]
  Интеграл расходится. Данное распределение не имеет математического ожидания.
\end{example}

\setcounter{equation}{0}
\section{Дисперсия случайной величины}
Пусть задана случайная величина $\xi$ на вероятностном пространстве $(\Omega, \mathcal{F}, \Prob)$. Определим дисперсию (центральный момент) случайной величины:
\[
  \Variance_{\xi} = \MExpect [ {(\xi - \MExpect_{\xi})}^2] = \int\limits_{-\infty}^{+\infty} {(x - \MExpect_{\xi})}^2 d \mathcal{P}_{\xi}
\]
\[
  \MExpect \left[ \xi^2 - 2 \xi \cdot \MExpect_{\xi} + (\MExpect_{\xi})^2 \right] = \MExpect_{\xi^2} - 2 \MExpect_{\xi} \cdot \MExpect_{\xi} + {(\MExpect_{\xi})}^2 = \MExpect_{\xi^2} - {(\MExpect_{\xi})}^2
\]
\[
  \Variance_{\xi} = \underset{a \in \mathbb{R}^1}{min} \MExpect [{(\xi - a)}^2]
\]
Минимум достигается в $a = \MExpect_{\xi}$. \\
Также определим среднеквадратическое отклонение (СКО) --- $\sqrt{\Variance_{\xi}}$
\subsection{Свойства дисперсии}
\begin{enumerate}
  \item Пусть $a, b$ --- константы, $\xi$ --- случайная величина
  \[
    \Variance [a \xi + b] = a^2 \Variance_{\xi}
  \]
  \begin{proof}
    \[
      \MExpect [{((a \xi + b) - \MExpect [a \xi + b])}^2] = a^2 \MExpect [{(\xi - \MExpect_{\xi})}^2] = a^2 \Variance_{\xi}
    \]
  \end{proof}
  \item $g(x) = x^2$, $x > 0$, $g(|\eta|),\; \eta = \xi - \MExpect_{\xi}$, $\varepsilon > 0:$
  \[
    \Prob \{ | \xi - \MExpect_{\xi} | \geqslant \varepsilon \} \leqslant \frac{\Variance_{\xi}}{\varepsilon^2} \text{ --- классическое нер-во Чебышёва}
  \]
\end{enumerate}
\begin{theorem}
  Пусть $\xi_1, \ldots, \xi_n$ --- независимые случайные величины.
  \[
    \forall i: \exists \MExpect_{\xi_i}: \MExpect [\xi_1 \cdot \ldots \cdot \xi_n] = \MExpect_{\xi_1} \cdot \ldots \cdot \MExpect_{\xi_n}
  \]
  Обратное не верно. \\
  $\xi, \eta$ --- независимые случайные величины. $\xi \sim x$, $\eta \sim y$, $\mathcal{P}_{\xi, \eta} = \mathcal{P}_{\xi} \times \mathcal{P}_{\eta}$
  \[
    \MExpect [\xi \cdot \eta] = \iint\limits_{\mathbb{R}^1 \times \mathbb{R}^1} x y d (\mathcal{P}_{\xi, \eta}) \overset{\text{по т. Фубини}}{=} \int\limits_{\mathbb{R}^1} x d \mathcal{P}_{\xi} \int\limits_{\mathbb{R}^1} y d \mathcal{P}_{\eta} = \MExpect_{\xi} \cdot \MExpect_{\eta}
  \]
\end{theorem}
\begin{example}
  Приведём пример, иллюстрирующий неверность обратного. Пусть $\xi, \theta$ --- независимые случайные величины, $\MExpect_{\xi} = 0$, $\MExpect_{\theta} = 0$, $\eta = \xi \cdot \theta$
  \[
    \MExpect [\xi \cdot \eta] = \MExpect[\xi^2 \cdot \theta] \overset{\text{(по т.1)}}{=} \MExpect_{\xi^2} \cdot \MExpect_{\theta} = 0, \MExpect_{\xi} \cdot \MExpect_{\eta} = 0
  \]
\end{example}
\begin{theorem}
  Пусть $\xi_1, \ldots, \xi_n$ --- независимые случайные величины, имеющие дисперсию $\forall i : \Variance_{\xi_i}$
  \[
    \Variance \left[ \sum\limits_{i = 1}^n \xi_i \right] = \sum\limits_{i = 1}^n \Variance_{\xi_i}
  \]
\end{theorem}
\begin{proof}
  Пусть $\xi, \eta$ --- независимые.
  \[
  \Variance [\xi + \eta] = \MExpect [{(\xi + \eta - \MExpect [\xi + \eta])}^2] = \MExpect [{((\xi - \MExpect_\xi) + (\eta - \MExpect_{\eta}))}^2] =
  \]
  \[
    = \MExpect [{(\xi - \MExpect_{\xi})}^2] + \MExpect [{(\eta - \MExpect_{\eta})}^2] + 2 \MExpect [(\xi - \MExpect_{\xi})(\eta - \MExpect_{\eta})]
  \]
  \[
    \MExpect_{\xi \eta} - \MExpect_{\xi} \cdot \MExpect_{\eta} + \MExpect_{\xi} \cdot \MExpect_{\eta} - \MExpect_{\xi} \cdot \MExpect_{\eta} = 0
  \]
\end{proof}
\begin{example}
  Пусть $\mu_n$ --- число успеха в $n$ испытаний Бернулли, $\mu_n = \sum\limits_{k = 1}^n \xi_k$
  \[
    \Variance_{\xi_k} = \MExpect_{\xi^2_k} - {(\MExpect_{\xi_k})}^2
  \]
  Распределение $\xi_k^2$ совпадает с $\xi_k$. Тогда
  \[
    \Variance_{\xi_k} = p - p^2 = p \cdot q
  \]
  \[
    \Variance_{\mu_n} = \sum\limits_{k = 1}^n \Variance_{\xi_k} = n \cdot p \cdot q
  \]
\end{example}

\section{Матрица ковариаций случайного вектора}
\begin{definition}
  Пусть задан вектор случайных величин $\overline{\xi} = (\xi_1, \ldots, \xi_n)$. \textit{Матрицей ковариаций} $\overline{\xi}$ называется матрица, элементами которой являются
  \[
    \underbrace{\MExpect {\left[ (\xi_i - \MExpect_{\xi_i})(\xi_j - \MExpect_{\xi_j})\right]}_{i, j = 1, \ldots, n}}_{cov(\xi_i, \xi_j)} = \sigma_{ij}
  \]
  То есть матрица ковариаций:
  \[
    R = {\{ \sigma_{ij} \}}_{i, j = 1, \ldots, n}
  \]
\end{definition}
\begin{definition}
  \textit{Корелляционным моментом} называют величину $k_{ij} = cov(\xi_i, \xi_j)$
\end{definition}
Если случайные величины $\xi_i, \xi_j$ независимы, то
\[
  \sigma_{ij} = 0
\]
Обратное не верно. \\
\begin{definition}
  Если $\sigma_{ij} = 0$, то $\xi_i, \xi_j$ называют \textit{некоррелированными случайными величинами}
\end{definition}
Очевидно, что:
\begin{itemize}
  \item $cov(\xi_i, \xi_j) = cov(\xi_j, \xi_i)$,
  \item $cov(\xi_i, \xi_i) = \Variance_{\xi_i}$,
  \item $cov(a\xi_i, \xi_j) = a \cdot cov(\xi_i, \xi_j)$, где $a$ --- константа.
\end{itemize}
Также
\[
  \Variance [\xi + \eta] = \Variance_{\xi} + \Variance_{\eta} + 2cov(\xi, \eta)
\]
Можно показать (по индукции), что
\[
  \Variance \left[ \sum\limits_{i = 1}^n \xi_i \right] = \sum\limits_{i = 1}^n \Variance_{\xi_i} + 2 \sum\limits_{i < j}^n cov(\xi_i, \xi_j)
\]
\begin{theorem}
  Пусть заданы
  \begin{itemize}
    \item вектор случайных величин $\overline{\xi} = (\xi_1, \ldots, \xi_n)$,
    \item матрица $C$, элементами которой являются константы $c$: $C = {\{ c_{ij}\}}_{m \times n}$, вектор $\overline{a} = {\{ a_i \}}_{i = 1, \ldots, m}$,
    \item вектор $\overline{b} = {\{ b_j \}}_{j = 1, \ldots, n}$
  \end{itemize}
  Рассмотрим вектор $\overline{\eta}$:
  \[
    \overline{\eta} = C \overline{\xi} + \overline{a}
  \]
  Тогда матрица ковариаций вектора $\overline{\eta}$:
  \[
    R_{\overline{\eta}} = C \cdot R_{\overline{\xi}} \cdot C^T
  \]
  \[
    R_{\overline{\xi} + \overline{b}} = R_{\overline{\xi}}
  \]
\end{theorem}
\begin{lemma}
  Пусть у вектора случайных величин $\overline{\xi} = (\xi_1, \ldots, \xi_n)$ существуют все ковариации $cov(\xi_i, \xi_j)$. Тогда при любом наборе вещественных констант ${\{ c_i \}}_{i = 1, \ldots, n}$
  \[
    \Variance [c_1 \xi_1 + \ldots + c_n \xi_n] = \sum\limits_{i, j = 1}^n \sigma_{ij} c_i c_j
  \]
\end{lemma}
\begin{proof}
  Пусть $\eta_n = c_1 \xi_1 + \ldots + c_n \xi_n$
  \[
    \eta_n - \MExpect_{\eta_n} = \sum\limits_{i = 1}^n c_i (\xi_i - \MExpect_{\xi_i})
  \]
  \[
    {(\eta_n - \MExpect_{\eta_n})}^2 = \sum\limits_{i, j = 1}^n c_i c_j (\xi_i - \MExpect_{\xi_i})(\xi_j - \MExpect_{\xi_j})
  \]
  Применим к обеим частям математическое ожидание:
  \[
    \Variance_{\eta_n} = \sum\limits_{i, j = 1}^n \sigma_{i j} c_i c_j \geqslant 0
  \]
  Тогда
  \[
    det \ R \geqslant 0
  \]
\end{proof}

\section{Коэффициент корреляции случайной величины}
Рассмотрим ситуацию, когда в векторе случайных величин содержится два элемента: $\overline{\xi} = (\xi_1, \xi_2)$. $R$ --- матрица ковариаций.
\[
  det \ R = \begin{vmatrix} \Variance_{\xi_1} & cov(\xi_1, \xi_2) \\
  cov(\xi_2, \xi_1) & \Variance_{\xi_2} \end{vmatrix}
\]
Отсюда следует, что
\[
  | cov(\xi_1, \xi_2) | \leqslant \sqrt{\Variance_{\xi_1} \cdot \Variance_{\xi_2} }
\]
Введём числовую характеристику --- степени зависимости двух случайных величин. Назовём её \textit{коэффициентом корреляции} двух случайных величин:
\[
  \rho (\xi_1, \xi_2) = \frac{cov(\xi_1, \xi_2)}{\sqrt{\Variance_{\xi_1} \cdot \Variance_{\xi_2}}}, \text{ где $\Variance_{\xi_1} \not= 0$ и $\Variance_{\xi_2} \not= 0$ }
\]
Отсюда следует, что $| \rho(\xi_1, \xi_2) | \leqslant 1$,\; $\rho$ --- безразмерная числовая характеристика.
\subsection{Свойства коэффициента корреляции}
\begin{enumerate}
  \item $\rho$ --- безразмерная числовая характеристика --- $| \rho(\xi_1, \xi_2) | \leqslant 1$
  \item Пусть заданы независимые случайные величины $\xi, \eta$. Тогда $\rho(\xi, \eta) = 0$. Обратное в общем случае не верно. \\
  \textbf{Но!} Если $\xi, \eta$ --- нормальные случайные величины то $\rho(\xi, \eta) = 0 \Rightarrow \xi, \eta$ --- независимые.
  \item $\xi, \eta$ линейно зависимы $\Leftrightarrow$ $| \rho(\xi, \eta) | = 1$.
  \end{enumerate}
  \begin{proof} \textit{(Свойство [3] --- необходимость)}
    Пусть $a, b$ --- константы, $a \neq 0$.\\
    $\eta = a\xi + b$, $\MExpect_{\eta} = a \MExpect_{\xi} + b$, $\Variance_{\eta} = a^2 \Variance_{\xi}$
    \[
      cov(\xi, \eta) = \MExpect [(\xi - \MExpect_{\xi})a(\xi - \MExpect_{\xi})] = a \Variance_{\xi}
    \]
    \[
      \rho (\xi, \eta) = \frac{a \Variance_{\xi}}{\sqrt{\Variance_{\xi} a^2 \Variance_{\xi}}} = \frac{a}{|a|} = sign \ a
    \]
  \end{proof}
  \begin{interjection}
    Для любой случайной величины, имеющей конечную ненулевую дисперсию, можно рассмотреть такую случайную величину:
    \[
      \xi_1 = \frac{\xi - \MExpect_{\xi}}{\sqrt{\Variance_{\xi}}}
    \]
    Если
    \begin{itemize}
      \item $\MExpect_{\xi_1} = 0$, то $\xi_1$ --- \textit{центрированная} случайная величина
      \item $\Variance_{\xi_1} = 1$, то $\xi_1$ --- \textit{нормированная} случайная величина
      \item $\MExpect_{\xi_1} = 0$ и $\Variance_{\xi_1} = 1$, то $\xi_1$ --- \textit{стандартизованная случайная величина}
    \end{itemize}
    То есть для любой случайной величины $\xi$ можно сопоставить $\xi_1$ --- стандартизованную случайную величину. Тогда
    \[
      \eta : \eta_1 = \frac{\eta - \MExpect_{\eta}}{\sqrt{\Variance_{\eta}}}
    \]
    \[
      \rho (\xi, \eta) = \MExpect_{\xi_1 \cdot \eta_1},
    \]
    где $\xi_1, \eta_1$ --- стандартизованные случайные величины. \\
    Рассмотрим такую дисперсию стандартизованных случайных величин:
    \[
      0 \leqslant \Variance [\xi_1 \pm \eta_1] = \MExpect [{(\xi_1 \pm \eta_1)}^2] = 2 \pm 2 \rho(\xi, \eta)
    \]
    $\MExpect_{\xi_1^2} = \Variance_{\xi_1} = 1, \MExpect_{\eta_1^2} = \Variance_{\eta_1} = 1$
  \end{interjection}
  \begin{proof} \textit{(Свойство [3] --- достаточность).}
    Рассмотрим $\rho(\xi, \eta) = 1$. Тогда
    \[
      \Variance [\xi_1 - \eta_1] = 2(1 - \rho(\xi, \eta)) = 0 \Rightarrow \Prob \{ \xi_1 - \eta_1 = 0 \} = 1 \Rightarrow \text{ линейно зав.}
    \]
    Рассмотрим $\rho(\xi, \eta) = -1$. Тогда
    \[
      \Variance [\xi_1 + \eta_1] = 2(1 + \rho(\xi, \eta)) = 0 \Rightarrow \Prob \{ \xi_1 + \eta_1 = 0 \} = 1 \Rightarrow \text{ линейно зав.}
    \]
  \end{proof}
\begin{definition}
  Две случайные величины называют \textit{положительно коррелированными}, если их коэффициент корреляции положительный. \\
  Так же и с отрицательным коэффициентом корреляции --- \textit{отрицательно коррелированными}. \\
  Если коэффициент корреляции случайных величин равен нулю, то такие случайные величины не коррелированы.
\end{definition}

\section{Моменты случайных величин произвольных порядков}
Кроме коэффициента корреляции существует немало других характеристик (например, корелляционное отношение).
\begin{definition}
  \textit{Моментом} (или начальным моментом) порядка $p > 0$ случайной величины $\xi$ на вероятностном пространстве $(\Omega, \mathcal{F}, \Prob)$ назовём $\MExpect_{\xi^p}$, при этом предполагается, что существует $\MExpect_{|\xi|^p} < +\infty$. По теореме о вычислении математического ожидания:
  \[
    \MExpect_{\xi^p} = \int\limits_{-\infty}^{+\infty} x^p d \mathcal{P}_{\xi} (x)
  \]
  \[
    \xi : \Omega \to \mathbb{R}^1 \ (\mathbb{R}^1, \mathcal{B} (\mathbb{R}^1), \mathcal{P}_{\xi})
  \]
\end{definition}
\begin{definition}
  \textit{Центральным моментом} порядка $p > 0$ случайной величины $\xi$ на вероятностном пространстве $(\Omega, \mathcal{F}, \Prob)$ назовём
  \[
    \MExpect [(\xi - \MExpect_{\xi})^p]
  \]
  При этом предполагается, что $\MExpect |(\xi - \MExpect_{\xi})|^p < +\infty$.
\end{definition}
\subsection{Свойства моментов случайных величин}
\begin{enumerate}
  \item Если существует абсолютный момент порядка $p$ случайной величины, то существуют все абсолютные моменты порядка $0 < q < p$, т.е.
  \[
    \forall q,\;p: \; 0 < q < p \;\;\;\; \exists \MExpect_{|\xi|^p} \Rightarrow \exists \MExpect_{|\xi|^q}
  \]
  Покажем это. Воспользуемся свойством: \\
  \textbf{Свойство (*)}: $\xi \leqslant \eta \Rightarrow \MExpect_{\xi} \leqslant \MExpect_{\eta}$ \label{3-5-ast}
  \[
    |x|^q \leqslant 1 + |x|^p
  \]
  \[
    |\xi|^q \leqslant 1 + |\xi|^p
  \]
  Тогда
  \[
    \MExpect_{|\xi|^q} \leqslant 1 + \MExpect_{|\xi|^p} < +\infty
  \]

  \item \textbf{Неравенство Гёльдера}. Пусть $p > 1$, $q > 1$,
  \[
    \frac{1}{p} + \frac{1}{q} = 1
  \]
  Также пусть существует $\MExpect_{|\xi|^p} < +\infty$, $\MExpect_{|\eta|^p} < +\infty$. Отсюда существует $\MExpect_{|\xi \cdot \eta|^p} < +\infty$. Тогда
  \[
    \MExpect_{|\xi \cdot \eta|} \leqslant \left[ \MExpect_{|\xi|^p} \right]^{\frac{1}{p}} \cdot \left[ \MExpect_{|\eta|^q} \right]^{\frac{1}{q}}
  \]
  \item \textbf{Неравенство Йенсена}. Пусть существует $\MExpect_{\xi}$, $g(x)$ --- выпуклая вниз борелевская функция. Тогда
  \[
    g(\MExpect_{\xi}) \leqslant \MExpect g(\xi)
  \]
  \begin{proof}
    Так как $g(x)$ выпукла вниз, то
    \[
      \forall y \in \mathbb{R}^1 \ \exists \lambda(y) : \forall x \in \mathbb{R}^1 \; g(x) \geqslant g(y) + (x-y) \cdot \lambda(y)
    \]
    Положим $x = \xi$, $y = \MExpect_{\xi}$. Тогда
    \[
      g(\xi) \geqslant g(\MExpect_{\xi}) + (\xi - \MExpect_{\xi}) \cdot \lambda (\MExpect_{\xi})
    \]
    Воспользуемся свойством \textbf{*}(\ref{3-5-ast}):
    \[
      \MExpect g(\xi) \geqslant g(\MExpect_{\xi})
    \]
  \end{proof}
  \item \textbf{Неравенство Ляпунова}. Пусть задана случайная величина $\xi$, имеющая математическое ожидание $\MExpect_{\xi}$, а также $p > q > 0$. Тогда
  \[
    \underbrace{\left[{\MExpect_{|\xi|^p}} \right]^{\frac{1}{p}}}_{\phi(p)}  \geqslant \left[ \MExpect_{|\xi|^q} \right]^{\frac{1}{q}}
  \]
  $\phi(p)$ монотонно не убывает.
  \begin{proof}
    Пусть $\frac{p}{q} = r > 1$. Рассмотрим борелевскую функцию $g(x) = |x|^r$. $r > 0$, значит, $g(x)$ выпуклая вниз. Обозначим $\eta = |\xi|^q$. Запишем неравенство Йенсена:
    \[
      \left[ \MExpect_{\eta} \right]^r \leqslant \MExpect_{|\eta|^r}, \
      \left[ \MExpect_{|\xi|^q} \right]^{\frac{p}{q}} \leqslant \MExpect_{|\xi|^p}
    \]
    Возведём в $\frac{1}{p}$:
    \[
      \left[ \MExpect_{|\xi|^q} \right]^{\frac{1}{q}} \leqslant \left[ \MExpect_{|\xi|^p} \right]^{\frac{1}{p}}
    \]
  \end{proof}
\end{enumerate}
\begin{definition}
  Пусть $k_1, \ldots, k_n \geqslant 0$ --- числа, а $\xi_1, \ldots, \xi_n$ --- упорядоченный набор случайных величин. Тогда
  \begin{enumerate}
    \item \label{3-5-1} \textit{Смешанным} моментом порядка ($k_1 + \ldots + k_n$) назовём
    \[
      \MExpect [\xi_1^{k_1} \cdot \xi_2^{k_2} \cdot \ldots \cdot \xi_n^{k_n}]
    \]
    \item \label{3-5-2} \textit{Центральным смешанным} моментом порядка ($k_1 + \ldots + k_n$) назовём
    \[
      \MExpect [(\xi_1 - \MExpect_{\xi_1})^{k_1} \cdot \ldots \cdot (\xi_n - \MExpect_{\xi_n})^{k_n}]
    \]
    Если $\xi_1, \ldots, \xi_n$ независимы, то \ref{3-5-1} и \ref{3-5-2} представляются произведением соответствующих моментов.
  \end{enumerate}
\end{definition}

\section{Законы распределения функций случайных величин}
Пусть определена случайная величина $\xi$, функция распределения этой случайной величины $F_{\xi}(x)$, а также, если $\xi$ абсолютно непрерывна, то функция плотности вероятности $f_{\xi}(x)$. \\
Рассмотрим борелевскую функцию одного аргумента:
\[
  g(\xi) = \eta
\]
Тогда
\[
  F_{\eta} (y) = \Prob \{ \eta \leqslant y \} = \Prob \{ g(\xi) \leqslant y \} = \Prob \{ \xi \in g^{-1} \{ (-\infty, y] \} \} =
\]
\[
  = \int\limits_{g^{-1} \{ (-\infty, y] \}} d \mathcal{P}_{\xi} \equiv \ldots
\]
\begin{addition}
  Вероятностная мера $\mathcal{P}_{\xi}$ однозначно восстанавливается по функции распределения $F_{\xi}$. Поэтому часто интеграл Лебега обозначают
  \[
    \int\limits_{\mathbb{R}^1} g(x) d \mathcal{P}_{\xi} = \int\limits_{\mathbb{R}^1} g(x) dF_{\xi} \text{ --- интеграл Лебега-Стилтьеса}
  \]
\end{addition}
\[
 \ldots \equiv \int\limits_{g^{-1} \{ (-\infty, y] \}} d F_{\xi} (x)
\]
Рассмотрим
\begin{itemize}
  \item $\eta = a \xi + b$, где $a, b$ --- константы
  \begin{enumerate}
    \item a > 0:
    \[
      F_{\eta} (y) = \Prob \{a \xi + b \leqslant y \} = \Prob \left\{ \xi \leqslant \frac{y-b}{a} \right\} = F_{\xi} \left( \frac{y-b}{a} \right)
    \]
    \item a < 0:
    \[
      F_{\eta} (y) = \Prob \{a \xi + b \leqslant y \} = \Prob \left\{ \xi \geqslant \frac{y-b}{a} \right\} =
    \]
    \[
      = 1 - F_{\xi} \left( \frac{y-b}{a}\right) + \Prob \left\{ \xi = \frac{y-b}{a} \right\}
    \]
  \end{enumerate}
  \item $\eta = \xi^2$
	\[
		F_{\eta}(y) =  \Prob \{\xi^2 \leqslant y \} = \Prob \{ -\sqrt{y} \leqslant \xi \leqslant \sqrt{y} \} =
	\]
	\[
		F_{\xi}(\sqrt{y})  - F_{\xi} (-\sqrt{ y }) + \Prob \{ \xi = -\sqrt{y} \}
	\]
\end{itemize}

Пусть задана абсолютно непрерывная случайная величина $\xi$, функция распределения этой случайной величины $F_{\xi} (x) $ и функция плотности вероятности $ f_{\xi} (x) $. \\
$ J = (a, b) \subset \mathbb{R}^1$, $g(x)$ --- непрерывная дифференцируемая функция, строго монотонна. $x \in J$, $g'(x) \neq 0$. 
\[
	x \in J,\; g'(x) \neq 0 \Rightarrow \exists g^{-1} (y), \ y \in g(J)
\] 
Рассмотрим случайную величину $g(\xi)$, пусть $g(\xi)$ строго возрастает.
\[
	F_{g(\xi)}(y) = \Prob \{ g(\xi) \leqslant y \} = \Prob \{ \xi \leqslant g^{-1}(y) \} = F_{\xi} (g^{-1}(y))
\]
\[
	\xi \sim \{ x \}, \ g(\xi) \sim \{ y \}
\]
Если существует функция плотности вероятности, то
\[
	F_{g(\xi)} (y) = F_{\xi} (\underbrace{g^{-1}(y)}_{h(y)}) = \int\limits_{-\infty}^{h(y)} f_{\xi} (x) dx = [x = h(z), z = g(x)] = 
\]
\[
	= \int\limits_{-\infty}^{y} \underbrace{f_{\xi} (h(z)) h'(z)}_{f_{g(\xi) }(z)} dz
\]
Пусть $g(x)$ строго убывает
\[
	F_{g(\xi)} (y) = \Prob \{ \xi \geqslant g^{-1}(y) \} = 1 - F_{\xi} (\underbrace{g^{-1}(y)}_{h(y)}) = 
\]
\[
	= \int\limits_{h(y)}^{-\infty} f_{\xi} (x) dx = [ x = h(z), z = g(x) ] = \int\limits_{y}^{-\infty} f_{\xi} (h(z)) h'(z) dz =
\]
\[
	- \int\limits_{-\infty}^y f_{\xi} (h(z)) h'(z) dz
\]
Если $g(x)$ строго монотонна:
\[
	fg_{(\xi)} (y) = f_{\xi} (g^{-1}(y)) \cdot [|g^{-1}(y)'|]
\]
Рассмотрим область значений
\[
	\xi : \sum\limits_{k = 1}^{n} [a_k, b_k], \ J_k = (a_k, b_k), \ g(x), \ x \in J_k
\]
$g(x)$ либо (строго) монотонно возрастает, либо (строго) монотонно убывает, непрерывно дифференцируема на каждом $J_k$, $g'(x) \neq 0$. \\
Введём обозначение:
\[
	h_k(y) = g^{-1}(y), \ y \in g(J_k)
\]
Тогда обобщённая формула имеет вид:
\[
	f_{g(\xi)} (y) = \sum\limits_{k = 1}^{n} f_{\xi} (h_k(y)) \cdot | {h'}_k(y) | \cdot I_{g(J_k)} (y)
\]
\begin{example}
	Пусть $\eta = g(\xi)$.
\begin{enumerate}
	\item $\eta = \xi^2$, $\xi$ --- абсолютно непрерывная случайная величина.
	\[
		y \leqslant 0: f_{\xi^2} (y) = 0, \ y > 0 : g(x) = x^2
	\]
	$J_1 = (-\infty, 0)$ --- $g(x)$ строго монотонно убывает \\
	$J_2 = (0, +\infty)$ --- $g(x)$ строго монотонно возрастает\\
	$y = x^2$, $x \in \mathbb{R}^1$
	\[
		x = \begin{cases}
		-\sqrt{y}, \ x < 0 \\
		\;\;\:\sqrt{y}, \ x \geqslant 0 
		\end{cases}
	\]
	Вычислим $h'(y)$
	\[
		h'(y) = \pm \frac{1}{2\sqrt{y}}, \ | h'(y) | = \left| \frac{1}{2\sqrt{y}} \right|
	\]
	Таким образом
	\[
		f_{\xi^2} (y) = \frac{1}{2 \sqrt{y}} \cdot \left[ f_{\xi} (-\sqrt{y}) + f_{\xi} (\sqrt{y}) \right], \ y > 0
	\]
	Рассмотрим:
	\[
		\xi \sim N(0, 1), \ f_{\xi} (x) = \frac{1}{\sqrt{2\pi}} e^{-\frac{x^2}{2}}
	\]
	\[
		f_{\xi^2} (y) = \frac{1}{\sqrt{2 \pi y}} e^{- \frac{y}{2}}, \ y > 0
	\]
	\item Пусть $\eta = |\xi|$, $g(x) = |x|$, $y = |x|$,
	\[
		x = \begin{cases}
		-y, \ x < 0 \\
		\;\;\:y,\ x \geqslant 0
		\end{cases}
	\]
	\[
		f_{|\xi|} (y) = f_{\xi} (-y) + f_{\xi} (y), \ y \geqslant 0
	\]
	
	\item Пусть $\eta = \sqrt{|\xi|}$
	\[
		f_{\sqrt{|\xi|}} (y) = 2y \cdot \left[ f_{\xi} (y^2) + f_{\xi} (-y^2) \right], \ y > 0
	\]
	
	\item Рассмотрим пример другого вида. Пусть имеется строго возрастающая функция распределения $F_{\xi} (x)$.  $F_{\xi} (\xi)$ --- случайная величина. Каков закон распределения?
	\[
		F_{F_{\xi}(\xi)} (x) = \Prob \{ F_{\xi} (\xi) \leqslant x \} = \Prob \{ \xi \leqslant F_{\xi}^{-1} (x) \} =
	\]
	\[
		= F_{\xi} (F_{\xi}^{-1} (x)) = x, \ 0 \leqslant x \leqslant 1
	\]
	\[
		\Prob \{ F_{\xi} (\xi) \leqslant x \} = \begin{cases}
			0, \ x < 0 \\
			x, \ 0 \leqslant x \leqslant 1 \\
			1, \ x > 1
		\end{cases} \overset{\textrm{def}}{=} F_{F_{\xi}(\xi)} (x)
	\]
	\[
		F_{\xi} : \mathbb{R}^1 \to [0, 1]
	\]
	\[
		F_{F_{\xi}(\xi)} \sim \textrm{U} [0, 1] \text{ --- равномерное распределение на отрезке}
	\]

	\item Пусть $\eta \sim \textrm{U} [0, 1]$, $F(x)$ --- непрерывная функция распределения. Тогда
	\[
		F_{F^{-1}(\eta)} (x) = \Prob \{ F^{-1} (\eta) \leqslant x \} = \Prob \{ \eta \leqslant F(x) \} = F_{\eta} (F(x)) = F(x)
	\]
	$y = F^{-1} (x)$, где $x \in [0, 1]$. \\
	Строим случайную величину с наперёд заданным распределением, используя случайную величину с равномерным распределением. \\
\end{enumerate}
\end{example}
Рассмотрим ситуацию, когда борелевская функция $g$ --- функция двух переменных. Пусть $\xi, \eta$ --- случайные величины, их функция распределения --- $F_{\xi, \eta} (x, y)$, $g(\xi, \eta)$, $z \in \mathbb{R}^1$.
	\[
		F_{g(\xi, \eta)} (z) = \Prob \{ g(\xi, \eta) \leqslant z \} = \iint\limits_{\{ x, y : g(x, y) \leqslant z \}} d F_{\xi, \eta} (x, y)
	\]
	Также пусть $g(x, y) = x + y$; $\xi, \eta$ --- независимые случайные величины
	\[
		F_{\xi + \eta} (z) = \iint\limits_{\{ x, y : x + y \leqslant z \}} dF_{\xi} (x) dF_{\eta} (y) =
	\]
	\[
		= \iint\limits_{\mathbb{R}^2} I_{\{ x + y \leqslant z \}} (x, y) dF_{\xi} (x) dF_{\eta} (y) =
	\]
	По теореме Фубини:
	\[
		= \int\limits_{-\infty}^{+\infty} dF_{\xi} (x) \left[ \int\limits_{-\infty}^{+\infty} I_{\{ x + y \leqslant z \}} (x, y) dF_{\eta} (y) \right] = \int\limits_{-\infty}^{+\infty} F_{\eta} (z-x) dF_{\xi} (x)
	\]
	\[
		F_{\xi + \eta} (z) = \int\limits_{-\infty}^{+\infty} F_{\xi} (z - y) dF_{\eta} (y)
	\]
	Если имеются функции распределения $F, G$, то
	\[
		H (z) = \underbrace{\int\limits_{-\infty}^{+\infty} F(z-x) dG(x) = \int\limits_{-\infty}^{+\infty} G(z - y) dF(y)}_{\text{свёртка $F$ и $G$ (композ.)}}
	\]
	Функция распределения суммы двух случайных независимых величин есть свёртка функций распределения слагаемых. \\
Пусть существует функция плотности вероятности $f_{\xi} (x), f_{\eta} (y)$. Тогда
\[
	F_{\xi + \eta} (z) = \int\limits_{-\infty}^{+\infty} \left[ \int\limits_{-\infty}^{z-y} f_{\xi} (u) du \right] \cdot f_{\eta} (y) dy = [\nu = u + y] =
\]
\[
	\int\limits_{-\infty}^{+\infty} \left[ \int\limits_{-\infty}^{z} f_{\xi} (\nu - y)d\nu \right] \cdot f_{\eta} (y) dy =
\]
По теореме Фубини:
\[
	\int\limits_{-\infty}^{z} \left[ \int\limits_{-\infty}^{+\infty} f_{\xi} (\nu - y) f_{\eta} (y) dy \right] d\nu
\]
Итак:
\[
	f_{\xi + \eta} (z) = \int\limits_{-\infty}^{+\infty} f_{\xi} (z - y) f_{\eta} (y) dy = \int\limits_{-\infty}^{+\infty} f_{\eta} (z - x) f_{\xi} (x) dx
\]
Пусть имеется набор независимых случайных величин $\xi_1, \ldots, \xi_n$, $\forall i : \xi_i \sim N (0,1)$. \\

Составим случайную величину, подчиняющуюся распределению $\chi^2$
\[
	\xi_1^2 + \ldots + \xi_n^2 = \chi_n^2
\]
\[
	f_{\chi_n^2} (x) = \begin{dcases*}
	\frac{x^{\frac{n}{2}-1} \cdot e^{-\frac{x}{2}} }{2^{\frac{n}{2}} \cdot \Gamma \left( \frac{n}{2} \right)}, \ x > 0 \\
	0, \ x \leqslant 0
	\end{dcases*}
\]
Составим распределение Стьюдента
\[
	t_n = \frac{\xi_0}{\sqrt{\frac{1}{n} \sum\limits_{i=1}^{n} \xi_i^2}} = \frac{\xi_0 \sqrt{n}}{\sqrt{\chi_n^2}} 
\]
где $\chi_n$ --- $\chi$-распределение с $n$ степенями свободы
\[
	\chi_n = \sqrt{\chi_n^2} \sim f_{\chi_n} (x) = \begin{dcases*}
	\frac{2 \cdot x^{n-1} \cdot e^{-\frac{x^2}{2}}}{2^{\frac{n}{2}} \cdot \Gamma \left( \frac{n}{2} \right)}, \ x > 0\\
	0, \ x \leqslant 0
	\end{dcases*}
\]
Можно показать, что
\[
	f_{t_n} (x) = \frac{\Gamma \left( \frac{n + 1}{2} \right)}{\sqrt{n \cdot \pi} \cdot \Gamma \left( \frac{n}{2} \right)} \left( 1 + \frac{x^2}{n} \right)^{-\frac{n+1}{2}}
\]
Если $n \to \infty$, то получим функцию плотности вероятности стандартного нормального распределения
\[
	f_{t_n} (x) \underset{n \to \infty}{\rightarrow} \frac{1}{\sqrt{2\pi}} e^{\frac{-x^2}{2}}
\]
Если $n = 1$, тогда получим функцию плотности вероятности распределения Коши с параметром 1
\[
	f_{t_n} (x) = \frac{1}{\pi (1 + x^2)}
\]
Рассмотрим независимые случайные величины $\xi, \eta$
\begin{itemize}
	\item $\xi \sim {\{ x_i \}}_{i = 1, 2, \ldots}$,
	\item $\eta \sim {\{ y_i \}}_{i = 1, 2, \ldots}$,
	\item $\xi + \eta \sim {\{ z_k \}}_{k = 1, 2, \ldots}$
\end{itemize}
\[
	\Prob \{ \xi + \eta = z_k \} = \sum\limits_{i} \Prob \{ \xi = x_i \} \Prob \{ \eta = z_k - x_i \} = 
\]
\[
	= \sum\limits_{j} \Prob \{ \eta = y_j \} \Prob \{ \xi = z_k - y_j \}
\]
Тогда функция распределения
\[
	F_{g(\xi, \eta)} (z) = \iint\limits_{\{ (x, y) : g(x, y) \leqslant z \}} dF_{\xi, \eta} (x, y)
\]
Рассмотрим произведение этих случайных величин. Пусть также $\xi, \eta$ --- независимые. Тогда функция плотности вероятности
\[
	f_{\xi \cdot \eta} (z) = \int\limits_{-\infty}^{+\infty} f_{\xi} (\frac{z}{y}) f_{\eta} (y) \frac{1}{|y|} dy
\]
\[
	f_{\frac{\xi}{\eta}} (z) = \int\limits_{-\infty}^{+\infty} f_{\xi} (zy) f_{\eta} (y) |y| dy = \frac{1}{z^2} \int\limits_{-\infty}^{+\infty} f_{\eta} \left(\frac{x}{z}\right) f_{\xi} (x) |x| dx
\]
Пусть задан вектор случайных величин с абсолютно непрерывным распределением
\[
	\overline{\xi} = (\xi_1, \ldots, \xi_n), \ f_{\xi} (x), \ x = (x_1, \ldots, x_n)
\]
Пусть $g_i$ --- борелевские функции
\[
	g_i: \mathbb{R}^n \to \mathbb{R}^1, \ i = 1, \ldots, n
\]
Рассмотрим
\[
	g : \mathbb{R}^n \to \mathbb{R}^n, \ \underset{x \in \mathbb{R}^n}{g(x)} = (g_1(x), \ldots, g_n(x))
\]
\[
	J(x) = \left| \frac{\partial(g_1, \ldots, g_n)}{\partial(x_1, \ldots, x_n)} \right| \neq 0
\]
Сконструируем вектор
\[
	\overline{\eta} = (\eta_1, \ldots, \eta_n), \ \eta_i = g_i (\overline{\xi})
\]
Его распределение описывается следующей функцией плотности вероятности
\[
	f_{\overline{\eta}} (x) = f_{\overline{\xi}} (g^{-1}(x)) = |J(g^{-1}(x))|^{-1}
\]
